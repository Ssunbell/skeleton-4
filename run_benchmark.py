"""
ë…ë¦½ ì‹¤í–‰í˜• ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸
Transformers vs vLLM ì„±ëŠ¥ ë¹„êµë¥¼ ë‹¨ë…ìœ¼ë¡œ ì‹¤í–‰
"""

from vllm_offline_inference import PerformanceBenchmark


def main():
    """
    Transformersì™€ vLLM ì„±ëŠ¥ ë¹„êµ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

    ì¸¡ì • í•­ëª©:
    - First Token Latency (TTFT): ì²« í† í° ìƒì„±ê¹Œì§€ ê±¸ë¦¬ëŠ” ì‹œê°„
    - Token/sec: ì´ˆë‹¹ ìƒì„± í† í° ìˆ˜
    - ì´ ì¶”ë¡  ì‹œê°„: ì „ì²´ ì¶”ë¡  ì™„ë£Œ ì‹œê°„
    - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: í”¼í¬ ë©”ëª¨ë¦¬
    - Throughput: ì´ˆë‹¹ ì²˜ë¦¬ í”„ë¡¬í”„íŠ¸ ìˆ˜
    """

    model_name = "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B"

    print("\n" + "=" * 60)
    print("ğŸ“Š Transformers vs vLLM ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 60)
    print("\nì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ë‹¤ìŒì„ ì¸¡ì •í•©ë‹ˆë‹¤:")
    print("  â€¢ First Token Latency (TTFT) - ì²« í† í° ìƒì„± ì†ë„")
    print("  â€¢ Token/sec - í† í° ìƒì„± ì²˜ë¦¬ëŸ‰")
    print("  â€¢ GPU Memory - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
    print("  â€¢ Throughput - ì´ˆë‹¹ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ëŸ‰")
    print("\n" + "=" * 60)

    # Text-to-SQL í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
    prompts = [
        "You are a SQL expert. Convert this to SQL: Find all users with age greater than 25",
        "You are a SQL expert. Convert this to SQL: Count total employees in sales department",
        "You are a SQL expert. Convert this to SQL: Show top 10 products by revenue",
        "You are a SQL expert. Convert this to SQL: Delete inactive user accounts",
        "You are a SQL expert. Convert this to SQL: Update email addresses for all admins",
    ]

    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ {len(prompts)}ê°œ ì¤€ë¹„")
    print(f"ğŸ¯ Max Tokens: 128\n")

    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark = PerformanceBenchmark(model_name)
    results = benchmark.compare(prompts, max_tokens=128)

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("âœ¨ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print("=" * 60)

    tf_results = results["transformers"]
    vllm_results = results["vllm"]

    print("\ní•µì‹¬ ì§€í‘œ ìš”ì•½:")
    print(
        f"  â€¢ vLLM Token ìƒì„± ì†ë„: {vllm_results['tokens_per_sec'] / tf_results['tokens_per_sec']:.2f}x ë” ë¹ ë¦„"
    )
    print(
        f"  â€¢ vLLM ì „ì²´ ì¶”ë¡  ì‹œê°„: {tf_results['total_inference_time'] / vllm_results['total_inference_time']:.2f}x ë” ë¹ ë¦„"
    )

    memory_diff = tf_results["peak_memory_mb"] - vllm_results["peak_memory_mb"]
    if memory_diff > 0:
        print(
            f"  â€¢ vLLM ë©”ëª¨ë¦¬ ì ˆê°: {memory_diff:.0f} MB ({memory_diff/tf_results['peak_memory_mb']*100:.1f}%)"
        )
    else:
        print(f"  â€¢ vLLM ë©”ëª¨ë¦¬ ì‚¬ìš©: {abs(memory_diff):.0f} MB ë” ì‚¬ìš©")

    print("\nvLLMì˜ PagedAttention ë•ë¶„ì— ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì²˜ë¦¬ ì†ë„ê°€")
    print("ë™ì‹œì— ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€")
    print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
